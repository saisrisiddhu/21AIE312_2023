{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# Rest of your code goes here.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a TensorFlow session and set the GPU device\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Specify the GPU device index to use (e.g., 1 for GPU 1)\n",
    "    gpu_index = 1\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[gpu_index], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Rest of your code goes here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import os\n",
    "from keras.datasets import fashion_mnist, cifar100\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from keras import optimizers\n",
    "from keras.layers.core import Lambda\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fake', 'Real']\n",
      "types of faces found: 2\n"
     ]
    }
   ],
   "source": [
    "#path=\"C:/Users/year1/Downloads/Dataset2\"\n",
    "#path=\"C:/Users/gaura/Downloads/Dataset2\"\n",
    "path=\"C:/Work2/data\"\n",
    "\n",
    "face_types=os.listdir(path)\n",
    "print(face_types)\n",
    "\n",
    "print(\"types of faces found:\",len(face_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces=[]\n",
    "\n",
    "for item in face_types:\n",
    "    all_faces=os.listdir(path + '/' + item)\n",
    "\n",
    "    for face in all_faces:\n",
    "        faces.append((item,str(path+'/'+item)+'/'+face))\n",
    "        #print(faces[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  face type                              image\n",
      "0      Fake  C:/Work2/data/Fake/000DmHuwCk.jpg\n",
      "1      Fake  C:/Work2/data/Fake/002zSNaHxO.jpg\n",
      "2      Fake  C:/Work2/data/Fake/0068uCvazN.jpg\n",
      "3      Fake  C:/Work2/data/Fake/006JOjVQfD.jpg\n",
      "4      Fake  C:/Work2/data/Fake/007ipsP3zJ.jpg\n",
      "       face type                              image\n",
      "189997      Real  C:/Work2/data/Real/ZzXQh6ieDP.jpg\n",
      "189998      Real  C:/Work2/data/Real/ZZxyD6eKQA.jpg\n",
      "189999      Real  C:/Work2/data/Real/zZYan2VV2B.jpg\n",
      "190000      Real  C:/Work2/data/Real/zZyeu2Y7fW.jpg\n",
      "190001      Real  C:/Work2/data/Real/ZZzD0gL408.jpg\n"
     ]
    }
   ],
   "source": [
    "# Build a dataframe        \n",
    "faces_df = pd.DataFrame(data=faces, columns=['face type', 'image'])\n",
    "print(faces_df.head())\n",
    "print(faces_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore if resized exists\n",
    "#creates resized folder\n",
    "import cv2\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "#path = \"C:/Users/year1/Downloads/Dataset2\"\n",
    "#path=\"C:/Users/gaura/Downloads/Dataset2\"\n",
    "path=\"D:/Work/data\"\n",
    "im_size = 227\n",
    "batch_size = 380  # adjust batch size as needed\n",
    "\n",
    "def image_generator():\n",
    "    for i in face_types:\n",
    "        data_path = os.path.join(path, str(i))\n",
    "        filenames = os.listdir(data_path)\n",
    "        for j in range(0, len(filenames), batch_size):\n",
    "            batch_filenames = filenames[j:j+batch_size]\n",
    "            batch_images = []\n",
    "            batch_labels = []\n",
    "            for f in batch_filenames:\n",
    "                img = cv2.imread(os.path.join(data_path, f))\n",
    "                if img is None:\n",
    "                    print(f\"Error: failed to read {os.path.join(data_path, f)}\")\n",
    "                    continue\n",
    "                img = cv2.resize(img, (im_size, im_size))\n",
    "                filename = os.path.splitext(f)[0] + '.jpg'  # change extension to .jpg\n",
    "                filepath = os.path.join(data_path, 'resized_Alexnet', filename)  # create output path\n",
    "                cv2.imwrite(filepath, img)  # write resized image to disk\n",
    "                batch_images.append(filepath)  # append file path to batch\n",
    "                batch_labels.append(i)\n",
    "            yield batch_images, np.array(batch_labels)\n",
    "\n",
    "# create output directories\n",
    "for i in face_types:\n",
    "    os.makedirs(os.path.join(path, str(i), 'resized_AlexNet'), exist_ok=True) # change for different network\n",
    "\n",
    "# Example usage\n",
    "gen = image_generator()\n",
    "for i in range(101):  # load 10 batches\n",
    "    batch_images, batch_labels = next(gen)\n",
    "    print(f\"Loaded batch {i+1} with {len(batch_images)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore if h5 exists\n",
    "#creates images.h5\n",
    "import os \n",
    "import cv2 \n",
    "import numpy as np \n",
    "import h5py \n",
    "#path = \"C:/Users/year1/Downloads/Dataset2/\" \n",
    "#path=\"C:/Users/gaura/Downloads/Dataset2\"\n",
    "path=\"C:/Work2/data\"\n",
    "im_size = 227 \n",
    "images = [] \n",
    "for i in face_types: \n",
    "    data_path = os.path.join(path, str(i), 'Augmented') \n",
    "    filenames = os.listdir(data_path) \n",
    "    for f in filenames: \n",
    "        filepath = os.path.join(data_path, f) \n",
    "        images.append(filepath) \n",
    "with h5py.File('images_AlexNet2.h5', 'w') as f: \n",
    "    dset = f.create_dataset('images', shape=(len(images), im_size, im_size, 3), dtype='float16')\n",
    "    for i, filepath in enumerate(images): \n",
    "        img = cv2.imread(filepath) \n",
    "        img = cv2.resize(img, (im_size, im_size)) \n",
    "        img = img.astype('float16') / 255.0 \n",
    "        dset[i] = img \n",
    "with h5py.File('images_AlexNet2.h5', 'r') as f: \n",
    "    dset = f['images'] \n",
    "    for i in range(len(images)): \n",
    "        img = dset[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Convert labels to numerical values using label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(faces_df['face type'].values)\n",
    "\n",
    "# Perform one hot encoding on the numerical labels\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_onehot = onehot_encoder.fit_transform(y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 55, 55, 96)        34944     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 23, 23, 256)       614656    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 11, 11, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 9, 9, 384)         885120    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 7, 7, 384)         1327488   \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 5, 5, 256)         884992    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 2, 2, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              4198400   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 8194      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,735,106\n",
      "Trainable params: 24,735,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(96, (11,11), strides=(4,4), activation='relu', input_shape=(227,227,3)))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "model.add(Conv2D(256, (5,5), strides=(1,1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "model.add(Conv2D(384, (3,3), strides=(1,1), activation='relu'))\n",
    "model.add(Conv2D(384, (3,3), strides=(1,1), activation='relu'))\n",
    "model.add(Conv2D(256, (3,3), strides=(1,1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fake', 'Real']\n",
      "types of faces found: 2\n"
     ]
    }
   ],
   "source": [
    "#path_test=\"C:/Users/year1/Downloads/Dataset_Copy_test\"\n",
    "#path_test=\"C:/Users/gaura/Downloads/Dataset_Copy_test3\"\n",
    "path_test=\"C:/WORK/Dataset_Copy_test3\"\n",
    "face_types_test=os.listdir(path_test)\n",
    "print(face_types_test)\n",
    "\n",
    "print(\"types of faces found:\",len(face_types_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_test=[]\n",
    "\n",
    "for item in face_types_test:\n",
    "    all_faces_test=os.listdir(path_test + '/' + item)\n",
    "\n",
    "    for face in all_faces_test:\n",
    "        faces_test.append((item,str(path_test+'/'+item)+'/'+face))\n",
    "        #print(faces[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  face type                                           image\n",
      "0      Fake  C:/WORK/Dataset_Copy_test3/Fake/0052ETBQFB.jpg\n",
      "1      Fake  C:/WORK/Dataset_Copy_test3/Fake/053UBPVSLY.jpg\n",
      "2      Fake  C:/WORK/Dataset_Copy_test3/Fake/056F3HHA5C.jpg\n",
      "3      Fake  C:/WORK/Dataset_Copy_test3/Fake/056XH8KUI0.jpg\n",
      "4      Fake  C:/WORK/Dataset_Copy_test3/Fake/058KLRF8OA.jpg\n",
      "     face type                                              image\n",
      "1995      Real  C:/WORK/Dataset_Copy_test3/Real/67_0_0_2017010...\n",
      "1996      Real  C:/WORK/Dataset_Copy_test3/Real/67_0_0_2017010...\n",
      "1997      Real  C:/WORK/Dataset_Copy_test3/Real/67_0_0_2017010...\n",
      "1998      Real  C:/WORK/Dataset_Copy_test3/Real/67_0_0_2017010...\n",
      "1999      Real  C:/WORK/Dataset_Copy_test3/Real/67_0_0_2017010...\n"
     ]
    }
   ],
   "source": [
    "faces_df_test = pd.DataFrame(data=faces_test, columns=['face type', 'image'])\n",
    "print(faces_df_test.head())\n",
    "print(faces_df_test.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#path = \"C:/Users/year1/Downloads/Dataset_Copy_test\"\n",
    "#path =\"C:/Users/gaura/Downloads/Dataset_Copy_test3\"\n",
    "path=\"C:/WORK/Dataset_Copy_test3\"\n",
    "im_size = 227\n",
    "face_types = ['Fake','Real']\n",
    "\n",
    "label_map_test = {label: idx for idx, label in enumerate(face_types)}\n",
    "\n",
    "images_test = []\n",
    "labels_test = []\n",
    "\n",
    "for label in face_types:\n",
    "    data_path = os.path.join(path, label)\n",
    "    filenames = [os.path.join(data_path, f) for f in os.listdir(data_path)]\n",
    "   \n",
    "    for filename in filenames:\n",
    "        img = cv2.imread(filename)\n",
    "        img = cv2.resize(img, (im_size, im_size))\n",
    "        images_test.append(img)\n",
    "        labels_test.append(label_map_test[label])\n",
    "\n",
    "images_test = np.array(images_test, dtype=np.float32)\n",
    "labels_test = np.array(labels_test, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 227, 227, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_test = np.array(images_test)\n",
    "\n",
    "images_test.shape\n",
    "\n",
    "images_test = images_test.astype('float16') / 255.0\n",
    "\n",
    "images_test.shape\n",
    "\n",
    "#images = np.array(images, dtype='float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Convert labels to numerical values using label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_test = label_encoder.fit_transform(faces_df_test['face type'].values)\n",
    "\n",
    "# Perform one hot encoding on the numerical labels\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_onehot_test = onehot_encoder.fit_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test, y_onehot_test = shuffle(images_test, y_onehot_test, random_state=7)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(images_test, y_onehot_test, test_size=0.9, random_state=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 1.0 epoch 1\n",
      "57/57 [==============================] - 9s 153ms/step - loss: 3.3846 - accuracy: 0.5061\n",
      "processing 2.0 epoch 1\n",
      "57/57 [==============================] - 9s 155ms/step - loss: 0.7013 - accuracy: 0.4939\n",
      "processing 3.0 epoch 1\n",
      "57/57 [==============================] - 9s 159ms/step - loss: 0.6934 - accuracy: 0.4939\n",
      "processing 4.0 epoch 1\n",
      "57/57 [==============================] - 9s 162ms/step - loss: 0.6922 - accuracy: 0.5067\n",
      "processing 5.0 epoch 1\n",
      "57/57 [==============================] - 9s 163ms/step - loss: 0.6913 - accuracy: 0.5061\n",
      "processing 6.0 epoch 1\n",
      "57/57 [==============================] - 9s 165ms/step - loss: 0.6888 - accuracy: 0.6311\n",
      "processing 7.0 epoch 1\n",
      "57/57 [==============================] - 10s 168ms/step - loss: 0.7179 - accuracy: 0.5061\n",
      "processing 8.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.6949 - accuracy: 0.4939\n",
      "processing 9.0 epoch 1\n",
      "57/57 [==============================] - 10s 169ms/step - loss: 0.6944 - accuracy: 0.4939\n",
      "processing 10.0 epoch 1\n",
      "57/57 [==============================] - 10s 170ms/step - loss: 0.6930 - accuracy: 0.4939\n",
      "processing 11.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.6912 - accuracy: 0.4939\n",
      "processing 12.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.6948 - accuracy: 0.4939\n",
      "processing 13.0 epoch 1\n",
      "57/57 [==============================] - 10s 169ms/step - loss: 0.6896 - accuracy: 0.5117\n",
      "processing 14.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.6913 - accuracy: 0.5061\n",
      "processing 15.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.6874 - accuracy: 0.5061\n",
      "processing 16.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.6844 - accuracy: 0.5172\n",
      "processing 17.0 epoch 1\n",
      "57/57 [==============================] - 10s 170ms/step - loss: 0.6763 - accuracy: 0.6711\n",
      "processing 18.0 epoch 1\n",
      "57/57 [==============================] - 10s 169ms/step - loss: 0.6791 - accuracy: 0.5061\n",
      "processing 19.0 epoch 1\n",
      "57/57 [==============================] - 10s 169ms/step - loss: 0.6676 - accuracy: 0.6300\n",
      "processing 20.0 epoch 1\n",
      "57/57 [==============================] - 10s 168ms/step - loss: 0.6721 - accuracy: 0.5828\n",
      "processing 21.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.6411 - accuracy: 0.6839\n",
      "processing 22.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.7304 - accuracy: 0.5061\n",
      "processing 23.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.6271 - accuracy: 0.6867\n",
      "processing 24.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.6727 - accuracy: 0.5911\n",
      "processing 25.0 epoch 1\n",
      "57/57 [==============================] - 10s 168ms/step - loss: 0.6720 - accuracy: 0.5878\n",
      "processing 26.0 epoch 1\n",
      "57/57 [==============================] - 10s 169ms/step - loss: 0.6461 - accuracy: 0.6572\n",
      "processing 27.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.6398 - accuracy: 0.5411\n",
      "processing 28.0 epoch 1\n",
      "57/57 [==============================] - 10s 178ms/step - loss: 0.7102 - accuracy: 0.5061\n",
      "processing 29.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.6392 - accuracy: 0.6256\n",
      "processing 30.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.6443 - accuracy: 0.7250\n",
      "processing 31.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.6410 - accuracy: 0.6611\n",
      "processing 32.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.6335 - accuracy: 0.6700\n",
      "processing 33.0 epoch 1\n",
      "57/57 [==============================] - 10s 170ms/step - loss: 0.6053 - accuracy: 0.7294\n",
      "processing 34.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.5907 - accuracy: 0.6983\n",
      "processing 35.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.5329 - accuracy: 0.7578\n",
      "processing 36.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.5055 - accuracy: 0.7561\n",
      "processing 37.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.5504 - accuracy: 0.7439\n",
      "processing 38.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.9593 - accuracy: 0.6122\n",
      "processing 39.0 epoch 1\n",
      "57/57 [==============================] - 10s 167ms/step - loss: 0.6998 - accuracy: 0.6250\n",
      "processing 40.0 epoch 1\n",
      "57/57 [==============================] - 10s 167ms/step - loss: 0.5821 - accuracy: 0.6856\n",
      "processing 41.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.5733 - accuracy: 0.7394\n",
      "processing 42.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.5646 - accuracy: 0.6961\n",
      "processing 43.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.5686 - accuracy: 0.6778\n",
      "processing 44.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.5378 - accuracy: 0.7589\n",
      "processing 45.0 epoch 1\n",
      "57/57 [==============================] - 10s 167ms/step - loss: 0.5426 - accuracy: 0.7378\n",
      "processing 46.0 epoch 1\n",
      "57/57 [==============================] - 10s 169ms/step - loss: 0.5404 - accuracy: 0.7311\n",
      "processing 47.0 epoch 1\n",
      "57/57 [==============================] - 10s 170ms/step - loss: 0.5227 - accuracy: 0.7550\n",
      "processing 48.0 epoch 1\n",
      "57/57 [==============================] - 10s 168ms/step - loss: 0.5396 - accuracy: 0.7289\n",
      "processing 49.0 epoch 1\n",
      "57/57 [==============================] - 10s 168ms/step - loss: 0.5054 - accuracy: 0.7622\n",
      "processing 50.0 epoch 1\n",
      "57/57 [==============================] - 10s 169ms/step - loss: 0.5122 - accuracy: 0.7406\n",
      "processing 51.0 epoch 1\n",
      "57/57 [==============================] - 10s 167ms/step - loss: 0.5139 - accuracy: 0.7428\n",
      "processing 52.0 epoch 1\n",
      "57/57 [==============================] - 10s 167ms/step - loss: 0.4933 - accuracy: 0.7644\n",
      "processing 53.0 epoch 1\n",
      "57/57 [==============================] - 9s 165ms/step - loss: 0.4911 - accuracy: 0.7672\n",
      "processing 54.0 epoch 1\n",
      "57/57 [==============================] - 10s 167ms/step - loss: 0.4647 - accuracy: 0.7850\n",
      "processing 55.0 epoch 1\n",
      "57/57 [==============================] - 10s 170ms/step - loss: 0.4549 - accuracy: 0.7856\n",
      "processing 56.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.4464 - accuracy: 0.7978\n",
      "processing 57.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.4351 - accuracy: 0.8094\n",
      "processing 58.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.4202 - accuracy: 0.8183\n",
      "processing 59.0 epoch 1\n",
      "57/57 [==============================] - 9s 165ms/step - loss: 0.4011 - accuracy: 0.8278\n",
      "processing 60.0 epoch 1\n",
      "57/57 [==============================] - 10s 169ms/step - loss: 0.4073 - accuracy: 0.8267\n",
      "processing 61.0 epoch 1\n",
      "57/57 [==============================] - 10s 168ms/step - loss: 0.3773 - accuracy: 0.8378\n",
      "processing 62.0 epoch 1\n",
      "57/57 [==============================] - 10s 169ms/step - loss: 0.3545 - accuracy: 0.8617\n",
      "processing 63.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.3421 - accuracy: 0.8678\n",
      "processing 64.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.3570 - accuracy: 0.8600\n",
      "processing 65.0 epoch 1\n",
      "57/57 [==============================] - 10s 167ms/step - loss: 0.3745 - accuracy: 0.8344\n",
      "processing 66.0 epoch 1\n",
      "57/57 [==============================] - 10s 170ms/step - loss: 0.3815 - accuracy: 0.8406\n",
      "processing 67.0 epoch 1\n",
      "57/57 [==============================] - 10s 168ms/step - loss: 0.3886 - accuracy: 0.8339\n",
      "processing 68.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.3037 - accuracy: 0.8806\n",
      "processing 69.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.3273 - accuracy: 0.8644\n",
      "processing 70.0 epoch 1\n",
      "57/57 [==============================] - 10s 169ms/step - loss: 0.3125 - accuracy: 0.8861\n",
      "processing 71.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.3275 - accuracy: 0.8667\n",
      "processing 72.0 epoch 1\n",
      "57/57 [==============================] - 10s 167ms/step - loss: 0.3134 - accuracy: 0.8750\n",
      "processing 73.0 epoch 1\n",
      "57/57 [==============================] - 9s 166ms/step - loss: 0.2568 - accuracy: 0.9011\n",
      "processing 74.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.4413 - accuracy: 0.7494\n",
      "processing 75.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.4014 - accuracy: 0.8333\n",
      "processing 76.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.3998 - accuracy: 0.8317\n",
      "processing 77.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.4092 - accuracy: 0.8200\n",
      "processing 78.0 epoch 1\n",
      "57/57 [==============================] - 10s 170ms/step - loss: 0.3143 - accuracy: 0.8944\n",
      "processing 79.0 epoch 1\n",
      "57/57 [==============================] - 10s 167ms/step - loss: 0.2884 - accuracy: 0.8756\n",
      "processing 80.0 epoch 1\n",
      "57/57 [==============================] - 10s 168ms/step - loss: 0.2997 - accuracy: 0.8678\n",
      "processing 81.0 epoch 1\n",
      "57/57 [==============================] - 10s 169ms/step - loss: 0.3676 - accuracy: 0.8706\n",
      "processing 82.0 epoch 1\n",
      "57/57 [==============================] - 10s 169ms/step - loss: 0.2920 - accuracy: 0.8683\n",
      "processing 83.0 epoch 1\n",
      "57/57 [==============================] - 10s 168ms/step - loss: 0.2474 - accuracy: 0.9083\n",
      "processing 84.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.2952 - accuracy: 0.8817\n",
      "processing 85.0 epoch 1\n",
      "57/57 [==============================] - 10s 168ms/step - loss: 0.2782 - accuracy: 0.8811\n",
      "processing 86.0 epoch 1\n",
      "57/57 [==============================] - 10s 170ms/step - loss: 0.2606 - accuracy: 0.8994\n",
      "processing 87.0 epoch 1\n",
      "57/57 [==============================] - 10s 170ms/step - loss: 0.2463 - accuracy: 0.9067\n",
      "processing 88.0 epoch 1\n",
      "57/57 [==============================] - 10s 169ms/step - loss: 0.2322 - accuracy: 0.9122\n",
      "processing 89.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.2378 - accuracy: 0.9106\n",
      "processing 90.0 epoch 1\n",
      "57/57 [==============================] - 10s 169ms/step - loss: 0.2401 - accuracy: 0.9128\n",
      "processing 91.0 epoch 1\n",
      "57/57 [==============================] - 10s 170ms/step - loss: 0.2352 - accuracy: 0.9111\n",
      "processing 92.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.2520 - accuracy: 0.9128\n",
      "processing 93.0 epoch 1\n",
      "57/57 [==============================] - 10s 169ms/step - loss: 0.2442 - accuracy: 0.9117\n",
      "processing 94.0 epoch 1\n",
      "57/57 [==============================] - 10s 168ms/step - loss: 0.2040 - accuracy: 0.9228\n",
      "processing 95.0 epoch 1\n",
      "57/57 [==============================] - 10s 166ms/step - loss: 0.1955 - accuracy: 0.9228\n",
      "processing 96.0 epoch 1\n",
      "57/57 [==============================] - 9s 165ms/step - loss: 0.2233 - accuracy: 0.9061\n",
      "processing 97.0 epoch 1\n",
      "57/57 [==============================] - 10s 168ms/step - loss: 0.2078 - accuracy: 0.9161\n",
      "processing 98.0 epoch 1\n",
      "57/57 [==============================] - 9s 165ms/step - loss: 0.1888 - accuracy: 0.9250\n",
      "processing 99.0 epoch 1\n",
      "57/57 [==============================] - 10s 170ms/step - loss: 0.1915 - accuracy: 0.9217\n",
      "processing 100.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.1894 - accuracy: 0.9206\n",
      "processing 101.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.1967 - accuracy: 0.9206\n",
      "processing 102.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.1854 - accuracy: 0.9278\n",
      "processing 103.0 epoch 1\n",
      "57/57 [==============================] - 10s 181ms/step - loss: 0.1654 - accuracy: 0.9333\n",
      "processing 104.0 epoch 1\n",
      "57/57 [==============================] - 10s 178ms/step - loss: 0.1625 - accuracy: 0.9339\n",
      "processing 105.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.1741 - accuracy: 0.9339\n",
      "processing 106.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.1804 - accuracy: 0.9328\n",
      "processing 107.0 epoch 1\n",
      "57/57 [==============================] - 10s 168ms/step - loss: 0.1726 - accuracy: 0.9372\n",
      "processing 108.0 epoch 1\n",
      "57/57 [==============================] - 9s 166ms/step - loss: 0.1594 - accuracy: 0.9394\n",
      "processing 109.0 epoch 1\n",
      "57/57 [==============================] - 10s 168ms/step - loss: 0.1422 - accuracy: 0.9500\n",
      "processing 110.0 epoch 1\n",
      "57/57 [==============================] - 10s 167ms/step - loss: 0.1515 - accuracy: 0.9433\n",
      "processing 111.0 epoch 1\n",
      "57/57 [==============================] - 10s 168ms/step - loss: 0.2992 - accuracy: 0.8972\n",
      "processing 112.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.2204 - accuracy: 0.9133\n",
      "processing 113.0 epoch 1\n",
      "57/57 [==============================] - 10s 168ms/step - loss: 0.2044 - accuracy: 0.9233\n",
      "processing 114.0 epoch 1\n",
      "57/57 [==============================] - 10s 169ms/step - loss: 0.1880 - accuracy: 0.9372\n",
      "processing 115.0 epoch 1\n",
      "57/57 [==============================] - 10s 167ms/step - loss: 0.1870 - accuracy: 0.9283\n",
      "processing 116.0 epoch 1\n",
      "57/57 [==============================] - 9s 166ms/step - loss: 0.1682 - accuracy: 0.9339\n",
      "processing 117.0 epoch 1\n",
      "57/57 [==============================] - 10s 166ms/step - loss: 0.1456 - accuracy: 0.9444\n",
      "processing 118.0 epoch 1\n",
      "57/57 [==============================] - 10s 168ms/step - loss: 0.1499 - accuracy: 0.9383\n",
      "processing 119.0 epoch 1\n",
      "57/57 [==============================] - 10s 169ms/step - loss: 0.1556 - accuracy: 0.9383\n",
      "processing 120.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.1477 - accuracy: 0.9456\n",
      "processing 121.0 epoch 1\n",
      "57/57 [==============================] - 11s 189ms/step - loss: 0.1421 - accuracy: 0.9494\n",
      "processing 122.0 epoch 1\n",
      "57/57 [==============================] - 10s 182ms/step - loss: 0.1447 - accuracy: 0.9428\n",
      "processing 123.0 epoch 1\n",
      "57/57 [==============================] - 11s 185ms/step - loss: 0.1342 - accuracy: 0.9544\n",
      "processing 124.0 epoch 1\n",
      "57/57 [==============================] - 10s 184ms/step - loss: 0.1593 - accuracy: 0.9439\n",
      "processing 125.0 epoch 1\n",
      "57/57 [==============================] - 11s 187ms/step - loss: 0.1617 - accuracy: 0.9461\n",
      "processing 126.0 epoch 1\n",
      "57/57 [==============================] - 10s 181ms/step - loss: 0.1305 - accuracy: 0.9539\n",
      "processing 127.0 epoch 1\n",
      "57/57 [==============================] - 10s 184ms/step - loss: 0.1260 - accuracy: 0.9522\n",
      "processing 128.0 epoch 1\n",
      "57/57 [==============================] - 11s 185ms/step - loss: 0.1209 - accuracy: 0.9556\n",
      "processing 129.0 epoch 1\n",
      "57/57 [==============================] - 11s 184ms/step - loss: 0.1350 - accuracy: 0.9511\n",
      "processing 130.0 epoch 1\n",
      "57/57 [==============================] - 10s 182ms/step - loss: 0.1365 - accuracy: 0.9506\n",
      "processing 131.0 epoch 1\n",
      "57/57 [==============================] - 11s 185ms/step - loss: 0.1261 - accuracy: 0.9556\n",
      "processing 132.0 epoch 1\n",
      "57/57 [==============================] - 11s 184ms/step - loss: 0.1197 - accuracy: 0.9561\n",
      "processing 133.0 epoch 1\n",
      "57/57 [==============================] - 10s 183ms/step - loss: 0.1169 - accuracy: 0.9561\n",
      "processing 134.0 epoch 1\n",
      "57/57 [==============================] - 10s 182ms/step - loss: 0.1143 - accuracy: 0.9589\n",
      "processing 135.0 epoch 1\n",
      "57/57 [==============================] - 11s 192ms/step - loss: 0.1236 - accuracy: 0.9517\n",
      "processing 136.0 epoch 1\n",
      "57/57 [==============================] - 11s 186ms/step - loss: 0.1468 - accuracy: 0.9394\n",
      "processing 137.0 epoch 1\n",
      "57/57 [==============================] - 10s 183ms/step - loss: 0.1294 - accuracy: 0.9483\n",
      "processing 138.0 epoch 1\n",
      "57/57 [==============================] - 12s 181ms/step - loss: 0.1057 - accuracy: 0.9561\n",
      "processing 139.0 epoch 1\n",
      "57/57 [==============================] - 11s 189ms/step - loss: 0.0988 - accuracy: 0.9583\n",
      "processing 140.0 epoch 1\n",
      "57/57 [==============================] - 11s 191ms/step - loss: 0.0995 - accuracy: 0.9617\n",
      "processing 141.0 epoch 1\n",
      "57/57 [==============================] - 11s 190ms/step - loss: 0.1225 - accuracy: 0.9533\n",
      "processing 142.0 epoch 1\n",
      "57/57 [==============================] - 11s 189ms/step - loss: 0.1108 - accuracy: 0.9561\n",
      "processing 143.0 epoch 1\n",
      "57/57 [==============================] - 11s 187ms/step - loss: 0.0933 - accuracy: 0.9639\n",
      "processing 144.0 epoch 1\n",
      "57/57 [==============================] - 11s 188ms/step - loss: 0.0875 - accuracy: 0.9683\n",
      "processing 145.0 epoch 1\n",
      "57/57 [==============================] - 11s 189ms/step - loss: 0.0865 - accuracy: 0.9628\n",
      "processing 146.0 epoch 1\n",
      "57/57 [==============================] - 11s 186ms/step - loss: 0.0960 - accuracy: 0.9617\n",
      "processing 147.0 epoch 1\n",
      "57/57 [==============================] - 11s 187ms/step - loss: 0.1001 - accuracy: 0.9589\n",
      "processing 148.0 epoch 1\n",
      "57/57 [==============================] - 11s 188ms/step - loss: 0.0976 - accuracy: 0.9639\n",
      "processing 149.0 epoch 1\n",
      "57/57 [==============================] - 11s 191ms/step - loss: 0.0903 - accuracy: 0.9639\n",
      "processing 150.0 epoch 1\n",
      "57/57 [==============================] - 11s 190ms/step - loss: 0.0887 - accuracy: 0.9644\n",
      "processing 151.0 epoch 1\n",
      "57/57 [==============================] - 11s 192ms/step - loss: 0.0967 - accuracy: 0.9628\n",
      "processing 152.0 epoch 1\n",
      "57/57 [==============================] - 11s 195ms/step - loss: 0.1033 - accuracy: 0.9633\n",
      "processing 153.0 epoch 1\n",
      "57/57 [==============================] - 11s 200ms/step - loss: 0.0913 - accuracy: 0.9644\n",
      "processing 154.0 epoch 1\n",
      "57/57 [==============================] - 11s 191ms/step - loss: 0.0776 - accuracy: 0.9722\n",
      "processing 155.0 epoch 1\n",
      "57/57 [==============================] - 11s 185ms/step - loss: 0.0758 - accuracy: 0.9700\n",
      "processing 156.0 epoch 1\n",
      "57/57 [==============================] - 11s 189ms/step - loss: 0.0751 - accuracy: 0.9717\n",
      "processing 157.0 epoch 1\n",
      "57/57 [==============================] - 11s 194ms/step - loss: 0.0833 - accuracy: 0.9700\n",
      "processing 158.0 epoch 1\n",
      "57/57 [==============================] - 11s 199ms/step - loss: 0.0891 - accuracy: 0.9667\n",
      "processing 159.0 epoch 1\n",
      "57/57 [==============================] - 11s 191ms/step - loss: 0.1017 - accuracy: 0.9617\n",
      "processing 160.0 epoch 1\n",
      "57/57 [==============================] - 11s 185ms/step - loss: 0.0795 - accuracy: 0.9722\n",
      "processing 161.0 epoch 1\n",
      "57/57 [==============================] - 10s 183ms/step - loss: 0.0763 - accuracy: 0.9694\n",
      "processing 162.0 epoch 1\n",
      "57/57 [==============================] - 11s 189ms/step - loss: 0.0743 - accuracy: 0.9750\n",
      "processing 163.0 epoch 1\n",
      "57/57 [==============================] - 11s 192ms/step - loss: 0.0833 - accuracy: 0.9672\n",
      "processing 164.0 epoch 1\n",
      "57/57 [==============================] - 11s 194ms/step - loss: 0.0880 - accuracy: 0.9678\n",
      "processing 165.0 epoch 1\n",
      "57/57 [==============================] - 11s 187ms/step - loss: 0.0791 - accuracy: 0.9722\n",
      "processing 166.0 epoch 1\n",
      "57/57 [==============================] - 11s 188ms/step - loss: 0.0731 - accuracy: 0.9733\n",
      "processing 167.0 epoch 1\n",
      "57/57 [==============================] - 11s 190ms/step - loss: 0.0678 - accuracy: 0.9733\n",
      "processing 168.0 epoch 1\n",
      "57/57 [==============================] - 11s 188ms/step - loss: 0.0655 - accuracy: 0.9744\n",
      "processing 169.0 epoch 1\n",
      "57/57 [==============================] - 11s 188ms/step - loss: 0.0690 - accuracy: 0.9744\n",
      "processing 170.0 epoch 1\n",
      "57/57 [==============================] - 11s 190ms/step - loss: 0.0672 - accuracy: 0.9722\n",
      "processing 171.0 epoch 1\n",
      "57/57 [==============================] - 11s 189ms/step - loss: 0.0729 - accuracy: 0.9717\n",
      "processing 172.0 epoch 1\n",
      "57/57 [==============================] - 11s 190ms/step - loss: 0.0775 - accuracy: 0.9711\n",
      "processing 173.0 epoch 1\n",
      "57/57 [==============================] - 11s 187ms/step - loss: 0.0643 - accuracy: 0.9728\n",
      "processing 174.0 epoch 1\n",
      "57/57 [==============================] - 11s 194ms/step - loss: 0.0616 - accuracy: 0.9744\n",
      "processing 175.0 epoch 1\n",
      "57/57 [==============================] - 12s 209ms/step - loss: 0.0616 - accuracy: 0.9761\n",
      "processing 176.0 epoch 1\n",
      "57/57 [==============================] - 11s 187ms/step - loss: 0.0625 - accuracy: 0.9767\n",
      "processing 177.0 epoch 1\n",
      "57/57 [==============================] - 12s 203ms/step - loss: 0.0661 - accuracy: 0.9756\n",
      "processing 178.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0614 - accuracy: 0.9778\n",
      "processing 179.0 epoch 1\n",
      "57/57 [==============================] - 11s 191ms/step - loss: 0.0572 - accuracy: 0.9767\n",
      "processing 180.0 epoch 1\n",
      "57/57 [==============================] - 11s 189ms/step - loss: 0.0585 - accuracy: 0.9778\n",
      "processing 181.0 epoch 1\n",
      "57/57 [==============================] - 11s 192ms/step - loss: 0.0538 - accuracy: 0.9783\n",
      "processing 182.0 epoch 1\n",
      "57/57 [==============================] - 11s 197ms/step - loss: 0.0608 - accuracy: 0.9789\n",
      "processing 183.0 epoch 1\n",
      "57/57 [==============================] - 12s 202ms/step - loss: 0.0724 - accuracy: 0.9750\n",
      "processing 184.0 epoch 1\n",
      "57/57 [==============================] - 11s 199ms/step - loss: 0.0730 - accuracy: 0.9739\n",
      "processing 185.0 epoch 1\n",
      "57/57 [==============================] - 11s 192ms/step - loss: 0.0638 - accuracy: 0.9756\n",
      "processing 186.0 epoch 1\n",
      "57/57 [==============================] - 11s 189ms/step - loss: 0.0617 - accuracy: 0.9767\n",
      "processing 187.0 epoch 1\n",
      "57/57 [==============================] - 11s 192ms/step - loss: 0.0607 - accuracy: 0.9778\n",
      "processing 188.0 epoch 1\n",
      "57/57 [==============================] - 12s 210ms/step - loss: 0.0623 - accuracy: 0.9772\n",
      "processing 189.0 epoch 1\n",
      "57/57 [==============================] - 11s 200ms/step - loss: 0.0751 - accuracy: 0.9739\n",
      "processing 190.0 epoch 1\n",
      "57/57 [==============================] - 11s 184ms/step - loss: 0.0697 - accuracy: 0.9733\n",
      "processing 191.0 epoch 1\n",
      "57/57 [==============================] - 10s 181ms/step - loss: 0.0736 - accuracy: 0.9728\n",
      "processing 192.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0977 - accuracy: 0.9622\n",
      "processing 193.0 epoch 1\n",
      "57/57 [==============================] - 10s 181ms/step - loss: 0.0763 - accuracy: 0.9667\n",
      "processing 194.0 epoch 1\n",
      "57/57 [==============================] - 10s 181ms/step - loss: 0.0782 - accuracy: 0.9722\n",
      "processing 195.0 epoch 1\n",
      "57/57 [==============================] - 10s 180ms/step - loss: 0.0693 - accuracy: 0.9750\n",
      "processing 196.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0695 - accuracy: 0.9739\n",
      "processing 197.0 epoch 1\n",
      "57/57 [==============================] - 12s 203ms/step - loss: 0.0701 - accuracy: 0.9750\n",
      "processing 198.0 epoch 1\n",
      "57/57 [==============================] - 10s 183ms/step - loss: 0.0735 - accuracy: 0.9750\n",
      "processing 199.0 epoch 1\n",
      "57/57 [==============================] - 11s 185ms/step - loss: 0.0738 - accuracy: 0.9739\n",
      "processing 200.0 epoch 1\n",
      "57/57 [==============================] - 10s 183ms/step - loss: 0.0686 - accuracy: 0.9739\n",
      "processing 201.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0647 - accuracy: 0.9772\n",
      "processing 202.0 epoch 1\n",
      "57/57 [==============================] - 10s 182ms/step - loss: 0.0657 - accuracy: 0.9772\n",
      "processing 203.0 epoch 1\n",
      "57/57 [==============================] - 10s 179ms/step - loss: 0.0704 - accuracy: 0.9761\n",
      "processing 204.0 epoch 1\n",
      "57/57 [==============================] - 10s 182ms/step - loss: 0.0714 - accuracy: 0.9761\n",
      "processing 205.0 epoch 1\n",
      "57/57 [==============================] - 11s 191ms/step - loss: 0.0659 - accuracy: 0.9761\n",
      "processing 206.0 epoch 1\n",
      "57/57 [==============================] - 11s 186ms/step - loss: 0.0612 - accuracy: 0.9794\n",
      "processing 207.0 epoch 1\n",
      "57/57 [==============================] - 11s 185ms/step - loss: 0.0617 - accuracy: 0.9789\n",
      "processing 208.0 epoch 1\n",
      "57/57 [==============================] - 11s 187ms/step - loss: 0.0598 - accuracy: 0.9794\n",
      "processing 209.0 epoch 1\n",
      "57/57 [==============================] - 10s 183ms/step - loss: 0.0658 - accuracy: 0.9761\n",
      "processing 210.0 epoch 1\n",
      "57/57 [==============================] - 10s 181ms/step - loss: 0.0730 - accuracy: 0.9733\n",
      "processing 211.0 epoch 1\n",
      "57/57 [==============================] - 10s 180ms/step - loss: 0.0639 - accuracy: 0.9772\n",
      "processing 212.0 epoch 1\n",
      "57/57 [==============================] - 10s 181ms/step - loss: 0.0561 - accuracy: 0.9806\n",
      "processing 213.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0507 - accuracy: 0.9817\n",
      "processing 214.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0488 - accuracy: 0.9800\n",
      "processing 215.0 epoch 1\n",
      "57/57 [==============================] - 10s 178ms/step - loss: 0.0652 - accuracy: 0.9794\n",
      "processing 216.0 epoch 1\n",
      "57/57 [==============================] - 10s 182ms/step - loss: 0.0684 - accuracy: 0.9772\n",
      "processing 217.0 epoch 1\n",
      "57/57 [==============================] - 10s 178ms/step - loss: 0.0514 - accuracy: 0.9822\n",
      "processing 218.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0482 - accuracy: 0.9828\n",
      "processing 219.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0489 - accuracy: 0.9817\n",
      "processing 220.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0559 - accuracy: 0.9811\n",
      "processing 221.0 epoch 1\n",
      "57/57 [==============================] - 10s 183ms/step - loss: 0.0698 - accuracy: 0.9750\n",
      "processing 222.0 epoch 1\n",
      "57/57 [==============================] - 10s 178ms/step - loss: 0.0593 - accuracy: 0.9783\n",
      "processing 223.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0561 - accuracy: 0.9772\n",
      "processing 224.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0559 - accuracy: 0.9800\n",
      "processing 225.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0625 - accuracy: 0.9789\n",
      "processing 226.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0803 - accuracy: 0.9739\n",
      "processing 227.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0865 - accuracy: 0.9706\n",
      "processing 228.0 epoch 1\n",
      "57/57 [==============================] - 10s 182ms/step - loss: 0.0628 - accuracy: 0.9778\n",
      "processing 229.0 epoch 1\n",
      "57/57 [==============================] - 11s 200ms/step - loss: 0.0570 - accuracy: 0.9822\n",
      "processing 230.0 epoch 1\n",
      "57/57 [==============================] - 11s 191ms/step - loss: 0.0546 - accuracy: 0.9806\n",
      "processing 231.0 epoch 1\n",
      "57/57 [==============================] - 10s 181ms/step - loss: 0.0567 - accuracy: 0.9844\n",
      "processing 232.0 epoch 1\n",
      "57/57 [==============================] - 10s 183ms/step - loss: 0.0635 - accuracy: 0.9800\n",
      "processing 233.0 epoch 1\n",
      "57/57 [==============================] - 11s 192ms/step - loss: 0.0681 - accuracy: 0.9789\n",
      "processing 234.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0662 - accuracy: 0.9800\n",
      "processing 235.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0674 - accuracy: 0.9767\n",
      "processing 236.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0656 - accuracy: 0.9778\n",
      "processing 237.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0641 - accuracy: 0.9783\n",
      "processing 238.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0604 - accuracy: 0.9783\n",
      "processing 239.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0552 - accuracy: 0.9817\n",
      "processing 240.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0494 - accuracy: 0.9811\n",
      "processing 241.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0511 - accuracy: 0.9817\n",
      "processing 242.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0542 - accuracy: 0.9794\n",
      "processing 243.0 epoch 1\n",
      "57/57 [==============================] - 10s 179ms/step - loss: 0.0504 - accuracy: 0.9839\n",
      "processing 244.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0460 - accuracy: 0.9861\n",
      "processing 245.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0549 - accuracy: 0.9789\n",
      "processing 246.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0553 - accuracy: 0.9783\n",
      "processing 247.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0622 - accuracy: 0.9744\n",
      "processing 248.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0910 - accuracy: 0.9656\n",
      "processing 249.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0881 - accuracy: 0.9683\n",
      "processing 250.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0584 - accuracy: 0.9811\n",
      "processing 251.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0500 - accuracy: 0.9817\n",
      "processing 252.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0470 - accuracy: 0.9844\n",
      "processing 253.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0597 - accuracy: 0.9789\n",
      "processing 254.0 epoch 1\n",
      "57/57 [==============================] - 10s 179ms/step - loss: 0.0620 - accuracy: 0.9789\n",
      "processing 255.0 epoch 1\n",
      "57/57 [==============================] - 10s 180ms/step - loss: 0.0458 - accuracy: 0.9850\n",
      "processing 256.0 epoch 1\n",
      "57/57 [==============================] - 10s 179ms/step - loss: 0.0471 - accuracy: 0.9844\n",
      "processing 257.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0834 - accuracy: 0.9667\n",
      "processing 258.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0589 - accuracy: 0.9783\n",
      "processing 259.0 epoch 1\n",
      "57/57 [==============================] - 10s 178ms/step - loss: 0.0478 - accuracy: 0.9844\n",
      "processing 260.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0475 - accuracy: 0.9850\n",
      "processing 261.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0488 - accuracy: 0.9817\n",
      "processing 262.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.0669 - accuracy: 0.9744\n",
      "processing 263.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0738 - accuracy: 0.9706\n",
      "processing 264.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0601 - accuracy: 0.9767\n",
      "processing 265.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0513 - accuracy: 0.9800\n",
      "processing 266.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0454 - accuracy: 0.9850\n",
      "processing 267.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0435 - accuracy: 0.9878\n",
      "processing 268.0 epoch 1\n",
      "57/57 [==============================] - 10s 180ms/step - loss: 0.0425 - accuracy: 0.9878\n",
      "processing 269.0 epoch 1\n",
      "57/57 [==============================] - 10s 178ms/step - loss: 0.0415 - accuracy: 0.9878\n",
      "processing 270.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0482 - accuracy: 0.9833\n",
      "processing 271.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0535 - accuracy: 0.9811\n",
      "processing 272.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0523 - accuracy: 0.9806\n",
      "processing 273.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0647 - accuracy: 0.9767\n",
      "processing 274.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.0549 - accuracy: 0.9800\n",
      "processing 275.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.0696 - accuracy: 0.9767\n",
      "processing 276.0 epoch 1\n",
      "57/57 [==============================] - 10s 178ms/step - loss: 0.0816 - accuracy: 0.9700\n",
      "processing 277.0 epoch 1\n",
      "57/57 [==============================] - 10s 178ms/step - loss: 0.0791 - accuracy: 0.9711\n",
      "processing 278.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0766 - accuracy: 0.9700\n",
      "processing 279.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.0646 - accuracy: 0.9783\n",
      "processing 280.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.0685 - accuracy: 0.9761\n",
      "processing 281.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0660 - accuracy: 0.9800\n",
      "processing 282.0 epoch 1\n",
      "57/57 [==============================] - 10s 178ms/step - loss: 0.0788 - accuracy: 0.9756\n",
      "processing 283.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0671 - accuracy: 0.9800\n",
      "processing 284.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0832 - accuracy: 0.9739\n",
      "processing 285.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0613 - accuracy: 0.9822\n",
      "processing 286.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0607 - accuracy: 0.9800\n",
      "processing 287.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0840 - accuracy: 0.9683\n",
      "processing 288.0 epoch 1\n",
      "57/57 [==============================] - 10s 179ms/step - loss: 0.0777 - accuracy: 0.9722\n",
      "processing 289.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0740 - accuracy: 0.9756\n",
      "processing 290.0 epoch 1\n",
      "57/57 [==============================] - 10s 170ms/step - loss: 0.0717 - accuracy: 0.9789\n",
      "processing 291.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0689 - accuracy: 0.9817\n",
      "processing 292.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0653 - accuracy: 0.9778\n",
      "processing 293.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0614 - accuracy: 0.9794\n",
      "processing 294.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0551 - accuracy: 0.9822\n",
      "processing 295.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0637 - accuracy: 0.9789\n",
      "processing 296.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0610 - accuracy: 0.9789\n",
      "processing 297.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.0573 - accuracy: 0.9817\n",
      "processing 298.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0641 - accuracy: 0.9794\n",
      "processing 299.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0577 - accuracy: 0.9811\n",
      "processing 300.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0508 - accuracy: 0.9844\n",
      "processing 301.0 epoch 1\n",
      "57/57 [==============================] - 10s 170ms/step - loss: 0.0512 - accuracy: 0.9850\n",
      "processing 302.0 epoch 1\n",
      "57/57 [==============================] - 10s 170ms/step - loss: 0.0476 - accuracy: 0.9861\n",
      "processing 303.0 epoch 1\n",
      "57/57 [==============================] - 10s 180ms/step - loss: 0.0457 - accuracy: 0.9850\n",
      "processing 304.0 epoch 1\n",
      "57/57 [==============================] - 10s 181ms/step - loss: 0.0480 - accuracy: 0.9828\n",
      "processing 305.0 epoch 1\n",
      "57/57 [==============================] - 10s 179ms/step - loss: 0.0469 - accuracy: 0.9872\n",
      "processing 306.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0563 - accuracy: 0.9844\n",
      "processing 307.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0549 - accuracy: 0.9822\n",
      "processing 308.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0550 - accuracy: 0.9828\n",
      "processing 309.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0631 - accuracy: 0.9778\n",
      "processing 310.0 epoch 1\n",
      "57/57 [==============================] - 10s 180ms/step - loss: 0.0603 - accuracy: 0.9817\n",
      "processing 311.0 epoch 1\n",
      "57/57 [==============================] - 10s 182ms/step - loss: 0.0707 - accuracy: 0.9767\n",
      "processing 312.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0601 - accuracy: 0.9800\n",
      "processing 313.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0596 - accuracy: 0.9789\n",
      "processing 314.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0578 - accuracy: 0.9767\n",
      "processing 315.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0569 - accuracy: 0.9783\n",
      "processing 316.0 epoch 1\n",
      "57/57 [==============================] - 10s 179ms/step - loss: 0.0477 - accuracy: 0.9822\n",
      "processing 317.0 epoch 1\n",
      "57/57 [==============================] - 10s 178ms/step - loss: 0.0419 - accuracy: 0.9872\n",
      "processing 318.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0393 - accuracy: 0.9856\n",
      "processing 319.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0405 - accuracy: 0.9850\n",
      "processing 320.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0447 - accuracy: 0.9878\n",
      "processing 321.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0507 - accuracy: 0.9856\n",
      "processing 322.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0474 - accuracy: 0.9872\n",
      "processing 323.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0466 - accuracy: 0.9811\n",
      "processing 324.0 epoch 1\n",
      "57/57 [==============================] - 10s 179ms/step - loss: 0.0357 - accuracy: 0.9872\n",
      "processing 325.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0464 - accuracy: 0.9822\n",
      "processing 326.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0560 - accuracy: 0.9789\n",
      "processing 327.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0473 - accuracy: 0.9872\n",
      "processing 328.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0549 - accuracy: 0.9861\n",
      "processing 329.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0443 - accuracy: 0.9883\n",
      "processing 330.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0404 - accuracy: 0.9883\n",
      "processing 331.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0417 - accuracy: 0.9878\n",
      "processing 332.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0463 - accuracy: 0.9839\n",
      "processing 333.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0423 - accuracy: 0.9850\n",
      "processing 334.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0578 - accuracy: 0.9761\n",
      "processing 335.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0399 - accuracy: 0.9867\n",
      "processing 336.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0504 - accuracy: 0.9839\n",
      "processing 337.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0601 - accuracy: 0.9833\n",
      "processing 338.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0515 - accuracy: 0.9839\n",
      "processing 339.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0604 - accuracy: 0.9767\n",
      "processing 340.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0516 - accuracy: 0.9778\n",
      "processing 341.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0454 - accuracy: 0.9850\n",
      "processing 342.0 epoch 1\n",
      "57/57 [==============================] - 10s 170ms/step - loss: 0.0479 - accuracy: 0.9839\n",
      "processing 343.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0414 - accuracy: 0.9850\n",
      "processing 344.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0385 - accuracy: 0.9850\n",
      "processing 345.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0359 - accuracy: 0.9878\n",
      "processing 346.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0340 - accuracy: 0.9872\n",
      "processing 347.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0336 - accuracy: 0.9883\n",
      "processing 348.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0327 - accuracy: 0.9883\n",
      "processing 349.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0314 - accuracy: 0.9894\n",
      "processing 350.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0313 - accuracy: 0.9906\n",
      "processing 351.0 epoch 1\n",
      "57/57 [==============================] - 10s 179ms/step - loss: 0.0297 - accuracy: 0.9911\n",
      "processing 352.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0311 - accuracy: 0.9911\n",
      "processing 353.0 epoch 1\n",
      "57/57 [==============================] - 10s 179ms/step - loss: 0.0310 - accuracy: 0.9889\n",
      "processing 354.0 epoch 1\n",
      "57/57 [==============================] - 10s 182ms/step - loss: 0.0316 - accuracy: 0.9894\n",
      "processing 355.0 epoch 1\n",
      "57/57 [==============================] - 10s 182ms/step - loss: 0.0331 - accuracy: 0.9878\n",
      "processing 356.0 epoch 1\n",
      "57/57 [==============================] - 10s 180ms/step - loss: 0.0313 - accuracy: 0.9889\n",
      "processing 357.0 epoch 1\n",
      "57/57 [==============================] - 10s 182ms/step - loss: 0.0335 - accuracy: 0.9889\n",
      "processing 358.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0319 - accuracy: 0.9894\n",
      "processing 359.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0298 - accuracy: 0.9894\n",
      "processing 360.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0422 - accuracy: 0.9833\n",
      "processing 361.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0298 - accuracy: 0.9900\n",
      "processing 362.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0373 - accuracy: 0.9878\n",
      "processing 363.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0520 - accuracy: 0.9806\n",
      "processing 364.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0513 - accuracy: 0.9811\n",
      "processing 365.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0314 - accuracy: 0.9889\n",
      "processing 366.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0341 - accuracy: 0.9894\n",
      "processing 367.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0446 - accuracy: 0.9850\n",
      "processing 368.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0308 - accuracy: 0.9911\n",
      "processing 369.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.0391 - accuracy: 0.9850\n",
      "processing 370.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0389 - accuracy: 0.9850\n",
      "processing 371.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0326 - accuracy: 0.9872\n",
      "processing 372.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0312 - accuracy: 0.9906\n",
      "processing 373.0 epoch 1\n",
      "57/57 [==============================] - 10s 178ms/step - loss: 0.0425 - accuracy: 0.9911\n",
      "processing 374.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0283 - accuracy: 0.9911\n",
      "processing 375.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0288 - accuracy: 0.9911\n",
      "processing 376.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0321 - accuracy: 0.9883\n",
      "processing 377.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0368 - accuracy: 0.9878\n",
      "processing 378.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0403 - accuracy: 0.9861\n",
      "processing 379.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.0395 - accuracy: 0.9872\n",
      "processing 380.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.0350 - accuracy: 0.9889\n",
      "processing 381.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0341 - accuracy: 0.9889\n",
      "processing 382.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0343 - accuracy: 0.9889\n",
      "processing 383.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0339 - accuracy: 0.9906\n",
      "processing 384.0 epoch 1\n",
      "57/57 [==============================] - 10s 170ms/step - loss: 0.0305 - accuracy: 0.9917\n",
      "processing 385.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0303 - accuracy: 0.9900\n",
      "processing 386.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0328 - accuracy: 0.9878\n",
      "processing 387.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0322 - accuracy: 0.9894\n",
      "processing 388.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0383 - accuracy: 0.9889\n",
      "processing 389.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.0344 - accuracy: 0.9889\n",
      "processing 390.0 epoch 1\n",
      "57/57 [==============================] - 10s 170ms/step - loss: 0.0310 - accuracy: 0.9900\n",
      "processing 391.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0295 - accuracy: 0.9900\n",
      "processing 392.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0289 - accuracy: 0.9894\n",
      "processing 393.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0302 - accuracy: 0.9889\n",
      "processing 394.0 epoch 1\n",
      "57/57 [==============================] - 10s 170ms/step - loss: 0.0296 - accuracy: 0.9900\n",
      "processing 395.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0255 - accuracy: 0.9917\n",
      "processing 396.0 epoch 1\n",
      "57/57 [==============================] - 10s 178ms/step - loss: 0.0312 - accuracy: 0.9878\n",
      "processing 397.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0253 - accuracy: 0.9900\n",
      "processing 398.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.0275 - accuracy: 0.9911\n",
      "processing 399.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0359 - accuracy: 0.9911\n",
      "processing 400.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0342 - accuracy: 0.9894\n",
      "processing 401.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0289 - accuracy: 0.9917\n",
      "processing 402.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0319 - accuracy: 0.9872\n",
      "processing 403.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0401 - accuracy: 0.9856\n",
      "processing 404.0 epoch 1\n",
      "57/57 [==============================] - 10s 179ms/step - loss: 0.0321 - accuracy: 0.9883\n",
      "processing 405.0 epoch 1\n",
      "57/57 [==============================] - 10s 180ms/step - loss: 0.0451 - accuracy: 0.9822\n",
      "processing 406.0 epoch 1\n",
      "57/57 [==============================] - 10s 180ms/step - loss: 0.0584 - accuracy: 0.9756\n",
      "processing 407.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0238 - accuracy: 0.9933\n",
      "processing 408.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.0383 - accuracy: 0.9861\n",
      "processing 409.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0399 - accuracy: 0.9850\n",
      "processing 410.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0304 - accuracy: 0.9900\n",
      "processing 411.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0317 - accuracy: 0.9906\n",
      "processing 412.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0353 - accuracy: 0.9894\n",
      "processing 413.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0334 - accuracy: 0.9900\n",
      "processing 414.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0295 - accuracy: 0.9894\n",
      "processing 415.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.0293 - accuracy: 0.9894\n",
      "processing 416.0 epoch 1\n",
      "57/57 [==============================] - 10s 169ms/step - loss: 0.0309 - accuracy: 0.9889\n",
      "processing 417.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0293 - accuracy: 0.9894\n",
      "processing 418.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0292 - accuracy: 0.9894\n",
      "processing 419.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0283 - accuracy: 0.9894\n",
      "processing 420.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0262 - accuracy: 0.9894\n",
      "processing 421.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.0253 - accuracy: 0.9900\n",
      "processing 422.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0244 - accuracy: 0.9922\n",
      "processing 423.0 epoch 1\n",
      "57/57 [==============================] - 10s 178ms/step - loss: 0.0255 - accuracy: 0.9900\n",
      "processing 424.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0226 - accuracy: 0.9922\n",
      "processing 425.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0212 - accuracy: 0.9922\n",
      "processing 426.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0208 - accuracy: 0.9933\n",
      "processing 427.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0207 - accuracy: 0.9944\n",
      "processing 428.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0205 - accuracy: 0.9939\n",
      "processing 429.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0206 - accuracy: 0.9939\n",
      "processing 430.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.0219 - accuracy: 0.9928\n",
      "processing 431.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0260 - accuracy: 0.9928\n",
      "processing 432.0 epoch 1\n",
      "57/57 [==============================] - 10s 178ms/step - loss: 0.0230 - accuracy: 0.9928\n",
      "processing 433.0 epoch 1\n",
      "57/57 [==============================] - 10s 179ms/step - loss: 0.0235 - accuracy: 0.9906\n",
      "processing 434.0 epoch 1\n",
      "57/57 [==============================] - 10s 178ms/step - loss: 0.0243 - accuracy: 0.9917\n",
      "processing 435.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0301 - accuracy: 0.9906\n",
      "processing 436.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0309 - accuracy: 0.9894\n",
      "processing 437.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0251 - accuracy: 0.9939\n",
      "processing 438.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0364 - accuracy: 0.9878\n",
      "processing 439.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0366 - accuracy: 0.9872\n",
      "processing 440.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0244 - accuracy: 0.9911\n",
      "processing 441.0 epoch 1\n",
      "57/57 [==============================] - 10s 170ms/step - loss: 0.0224 - accuracy: 0.9928\n",
      "processing 442.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.0286 - accuracy: 0.9928\n",
      "processing 443.0 epoch 1\n",
      "57/57 [==============================] - 10s 181ms/step - loss: 0.0302 - accuracy: 0.9922\n",
      "processing 444.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0269 - accuracy: 0.9917\n",
      "processing 445.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0240 - accuracy: 0.9933\n",
      "processing 446.0 epoch 1\n",
      "57/57 [==============================] - 10s 171ms/step - loss: 0.0261 - accuracy: 0.9900\n",
      "processing 447.0 epoch 1\n",
      "57/57 [==============================] - 10s 178ms/step - loss: 0.0246 - accuracy: 0.9928\n",
      "processing 448.0 epoch 1\n",
      "57/57 [==============================] - 10s 178ms/step - loss: 0.0240 - accuracy: 0.9928\n",
      "processing 449.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0223 - accuracy: 0.9939\n",
      "processing 450.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0215 - accuracy: 0.9922\n",
      "processing 451.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0236 - accuracy: 0.9922\n",
      "processing 452.0 epoch 1\n",
      "57/57 [==============================] - 10s 172ms/step - loss: 0.0262 - accuracy: 0.9911\n",
      "processing 453.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0270 - accuracy: 0.9917\n",
      "processing 454.0 epoch 1\n",
      "57/57 [==============================] - 10s 179ms/step - loss: 0.0262 - accuracy: 0.9917\n",
      "processing 455.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0254 - accuracy: 0.9906\n",
      "processing 456.0 epoch 1\n",
      "57/57 [==============================] - 11s 184ms/step - loss: 0.0231 - accuracy: 0.9917\n",
      "processing 457.0 epoch 1\n",
      "57/57 [==============================] - 10s 180ms/step - loss: 0.0211 - accuracy: 0.9939\n",
      "processing 458.0 epoch 1\n",
      "57/57 [==============================] - 10s 181ms/step - loss: 0.0189 - accuracy: 0.9950\n",
      "processing 459.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0187 - accuracy: 0.9939\n",
      "processing 460.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0205 - accuracy: 0.9933\n",
      "processing 461.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0182 - accuracy: 0.9939\n",
      "processing 462.0 epoch 1\n",
      "57/57 [==============================] - 10s 178ms/step - loss: 0.0178 - accuracy: 0.9944\n",
      "processing 463.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0202 - accuracy: 0.9922\n",
      "processing 464.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0236 - accuracy: 0.9922\n",
      "processing 465.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0278 - accuracy: 0.9906\n",
      "processing 466.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0324 - accuracy: 0.9878\n",
      "processing 467.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0354 - accuracy: 0.9878\n",
      "processing 468.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0340 - accuracy: 0.9867\n",
      "processing 469.0 epoch 1\n",
      "57/57 [==============================] - 10s 180ms/step - loss: 0.0303 - accuracy: 0.9900\n",
      "processing 470.0 epoch 1\n",
      "57/57 [==============================] - 10s 181ms/step - loss: 0.0284 - accuracy: 0.9889\n",
      "processing 471.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0259 - accuracy: 0.9922\n",
      "processing 472.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0265 - accuracy: 0.9900\n",
      "processing 473.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0283 - accuracy: 0.9906\n",
      "processing 474.0 epoch 1\n",
      "57/57 [==============================] - 10s 182ms/step - loss: 0.0303 - accuracy: 0.9900\n",
      "processing 475.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0277 - accuracy: 0.9911\n",
      "processing 476.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0244 - accuracy: 0.9911\n",
      "processing 477.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0258 - accuracy: 0.9917\n",
      "processing 478.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0260 - accuracy: 0.9911\n",
      "processing 479.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0239 - accuracy: 0.9917\n",
      "processing 480.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0286 - accuracy: 0.9889\n",
      "processing 481.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0291 - accuracy: 0.9883\n",
      "processing 482.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0255 - accuracy: 0.9922\n",
      "processing 483.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0320 - accuracy: 0.9889\n",
      "processing 484.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0373 - accuracy: 0.9878\n",
      "processing 485.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0374 - accuracy: 0.9872\n",
      "processing 486.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0344 - accuracy: 0.9878\n",
      "processing 487.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0362 - accuracy: 0.9878\n",
      "processing 488.0 epoch 1\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.0330 - accuracy: 0.9894\n",
      "processing 489.0 epoch 1\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.0281 - accuracy: 0.9894\n",
      "processing 490.0 epoch 1\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0299 - accuracy: 0.9872\n",
      "processing 491.0 epoch 1\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0314 - accuracy: 0.9894\n",
      "processing 492.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0307 - accuracy: 0.9900\n",
      "processing 493.0 epoch 1\n",
      "57/57 [==============================] - 10s 178ms/step - loss: 0.0318 - accuracy: 0.9900\n",
      "processing 494.0 epoch 1\n",
      "57/57 [==============================] - 10s 179ms/step - loss: 0.0342 - accuracy: 0.9883\n",
      "processing 495.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0316 - accuracy: 0.9894\n",
      "processing 496.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0340 - accuracy: 0.9883\n",
      "processing 497.0 epoch 1\n",
      "57/57 [==============================] - 10s 180ms/step - loss: 0.0286 - accuracy: 0.9894\n",
      "processing 498.0 epoch 1\n",
      "57/57 [==============================] - 10s 179ms/step - loss: 0.0304 - accuracy: 0.9883\n",
      "processing 499.0 epoch 1\n",
      "57/57 [==============================] - 10s 179ms/step - loss: 0.0291 - accuracy: 0.9894\n",
      "processing 500.0 epoch 1\n",
      "57/57 [==============================] - 10s 177ms/step - loss: 0.0276 - accuracy: 0.9900\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "# open the .h5 file and get the dataset shape\n",
    "with h5py.File('images_AlexNet2.h5', 'r') as file:\n",
    "    num_images = file['images'].shape[0]\n",
    "batch_size = 190\n",
    "num_epochs = 1\n",
    "\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, 95000, batch_size):\n",
    "        with h5py.File('images_AlexNet2.h5', 'r') as file:\n",
    "            fake_images_batch = file['images'][i:i+batch_size]\n",
    "            real_images_batch = file['images'][95000+i:95000+i+batch_size]\n",
    "            images_batch = np.concatenate([fake_images_batch, real_images_batch])\n",
    "            fake_labels_batch = y_onehot[i:i+batch_size]\n",
    "            real_labels_batch = y_onehot[95000+i:95000+i+batch_size]\n",
    "            labels_batch = np.concatenate([fake_labels_batch, real_labels_batch])\n",
    "            print(\"processing\",(i/190)+1,\"epoch\",epoch+1)\n",
    "            history=model.train_on_batch(images_batch, labels_batch)\n",
    "            train_losses.append(history[0])\n",
    "            val_loss=model.evaluate(x_test,y_test)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "plt.plot(train_losses,label='TrainingLoss')\n",
    "plt.plot(val_losses,label='ValidationLoss')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()           \n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 149ms/step - loss: 0.0303 - accuracy: 0.9850\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:/Work2/model_AlexNet1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       111\n",
      "           1       1.00      0.97      0.98        89\n",
      "\n",
      "    accuracy                           0.98       200\n",
      "   macro avg       0.99      0.98      0.98       200\n",
      "weighted avg       0.99      0.98      0.98       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(x_train)\n",
    "\n",
    "# Convert the predictions to binary labels\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_train, axis=1)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('C:/Work2/model_AlexNet1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fake', 'Real']\n",
      "types of faces found: 2\n"
     ]
    }
   ],
   "source": [
    "#path_test=\"C:/Users/year1/Downloads/Dataset_Copy_test\"\n",
    "#path_test=\"C:/Users/gaura/Downloads/Dataset_Copy_test3\"\n",
    "path_test=\"C:/WORK/Dataset_Copy_test4\"\n",
    "face_types_test=os.listdir(path_test)\n",
    "print(face_types_test)\n",
    "\n",
    "print(\"types of faces found:\",len(face_types_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_test=[]\n",
    "\n",
    "for item in face_types_test:\n",
    "    all_faces_test=os.listdir(path_test + '/' + item)\n",
    "\n",
    "    for face in all_faces_test:\n",
    "        faces_test.append((item,str(path_test+'/'+item)+'/'+face))\n",
    "        #print(faces[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  face type                                              image\n",
      "0      Fake  C:/WORK/Dataset_Copy_test4/Fake/0052ETBQFB_aug...\n",
      "1      Fake  C:/WORK/Dataset_Copy_test4/Fake/0052ETBQFB_aug...\n",
      "2      Fake  C:/WORK/Dataset_Copy_test4/Fake/0052ETBQFB_aug...\n",
      "3      Fake  C:/WORK/Dataset_Copy_test4/Fake/053UBPVSLY_aug...\n",
      "4      Fake  C:/WORK/Dataset_Copy_test4/Fake/053UBPVSLY_aug...\n",
      "     face type                                              image\n",
      "5995      Real  C:/WORK/Dataset_Copy_test4/Real/67_0_0_2017010...\n",
      "5996      Real  C:/WORK/Dataset_Copy_test4/Real/67_0_0_2017010...\n",
      "5997      Real  C:/WORK/Dataset_Copy_test4/Real/67_0_0_2017010...\n",
      "5998      Real  C:/WORK/Dataset_Copy_test4/Real/67_0_0_2017010...\n",
      "5999      Real  C:/WORK/Dataset_Copy_test4/Real/67_0_0_2017010...\n"
     ]
    }
   ],
   "source": [
    "faces_df_test = pd.DataFrame(data=faces_test, columns=['face type', 'image'])\n",
    "print(faces_df_test.head())\n",
    "print(faces_df_test.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#path = \"C:/Users/year1/Downloads/Dataset_Copy_test\"\n",
    "#path =\"C:/Users/gaura/Downloads/Dataset_Copy_test3\"\n",
    "path=\"C:/WORK/Dataset_Copy_test4\"\n",
    "im_size = 227\n",
    "face_types = ['Fake','Real']\n",
    "\n",
    "label_map_test = {label: idx for idx, label in enumerate(face_types)}\n",
    "\n",
    "images_test = []\n",
    "labels_test = []\n",
    "\n",
    "for label in face_types:\n",
    "    data_path = os.path.join(path, label)\n",
    "    filenames = [os.path.join(data_path, f) for f in os.listdir(data_path)]\n",
    "   \n",
    "    for filename in filenames:\n",
    "        img = cv2.imread(filename)\n",
    "        img = cv2.resize(img, (im_size, im_size))\n",
    "        images_test.append(img)\n",
    "        labels_test.append(label_map_test[label])\n",
    "\n",
    "images_test = np.array(images_test, dtype=np.float32)\n",
    "labels_test = np.array(labels_test, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 227, 227, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_test = np.array(images_test)\n",
    "\n",
    "images_test.shape\n",
    "\n",
    "images_test = images_test.astype('float16') / 255.0\n",
    "\n",
    "images_test.shape\n",
    "\n",
    "#images = np.array(images, dtype='float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Convert labels to numerical values using label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_test = label_encoder.fit_transform(faces_df_test['face type'].values)\n",
    "\n",
    "# Perform one hot encoding on the numerical labels\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_onehot_test = onehot_encoder.fit_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test, y_onehot_test = shuffle(images_test, y_onehot_test, random_state=7)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(images_test, y_onehot_test, test_size=0.9, random_state=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 2s 82ms/step - loss: 0.0319 - accuracy: 0.9850\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m y_pred_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m y_test_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_test, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "precision = precision_score(y_test_classes, y_pred_classes)\n",
    "recall = recall_score(y_test_classes, y_pred_classes)\n",
    "f1 = f1_score(y_test_classes,y_pred_classes)\n",
    "auroc = roc_auc_score(y_test_classes,y_pred_classes)\n",
    "\n",
    "print(\"Accuracy is =\", accuracy*100,\"%\")\n",
    "print(\"Precision is =\", precision*100,\"%\")\n",
    "print(\"Recall is =\", recall*100,\"%\")\n",
    "print(\"F1-Score is =\", f1*100,\"%\")\n",
    "print(\"AUROC is =\", auroc*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       308\n",
      "           1       1.00      0.97      0.98       292\n",
      "\n",
      "    accuracy                           0.98       600\n",
      "   macro avg       0.99      0.98      0.98       600\n",
      "weighted avg       0.99      0.98      0.98       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(x_train)\n",
    "\n",
    "# Convert the predictions to binary labels\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_train, axis=1)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (3.33.1)\n",
      "Requirement already satisfied: orjson in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (3.9.0)\n",
      "Requirement already satisfied: fastapi in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (0.96.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (1.23.5)\n",
      "Requirement already satisfied: httpx in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (0.24.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: python-multipart in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: gradio-client>=0.2.4 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (0.2.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (4.4.0)\n",
      "Requirement already satisfied: markupsafe in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (0.22.0)\n",
      "Requirement already satisfied: aiofiles in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (23.1.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (3.7.1)\n",
      "Requirement already satisfied: altair>=4.2.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (5.0.1)\n",
      "Requirement already satisfied: websockets>=10.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (11.0.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (3.8.3)\n",
      "Requirement already satisfied: pydub in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (0.3.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (1.10.8)\n",
      "Requirement already satisfied: requests in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (2.28.1)\n",
      "Requirement already satisfied: semantic-version in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: pygments>=2.12.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (2.15.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (1.5.3)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (0.3.0)\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from altair>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio-client>=0.2.4->gradio) (22.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio-client>=0.2.4->gradio) (2023.5.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (4.65.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (3.12.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from pandas->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from pandas->gradio) (2022.7.1)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (8.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from aiohttp->gradio) (1.8.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from aiohttp->gradio) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from aiohttp->gradio) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from aiohttp->gradio) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from aiohttp->gradio) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from aiohttp->gradio) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from aiohttp->gradio) (2.0.4)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from fastapi->gradio) (0.27.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from httpx->gradio) (2022.12.7)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from httpx->gradio) (0.17.2)\n",
      "Requirement already satisfied: idna in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from httpx->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from httpx->gradio) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from matplotlib->gradio) (4.39.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from matplotlib->gradio) (5.12.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from matplotlib->gradio) (1.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from matplotlib->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from matplotlib->gradio) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests->gradio) (1.26.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from click>=7.0->uvicorn>=0.14.0->gradio) (0.4.6)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.5.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->gradio) (3.11.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: uc-micro-py in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img):\n",
    "    img_3d=img.reshape(-1,227,227,3)\n",
    "    prediction=model.predict(img_3d)[0]\n",
    "    return {face_types[i]: float (prediction[i]) for i in range(2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\gradio\\inputs.py:259: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\gradio\\inputs.py:262: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  super().__init__(\n",
      "C:\\Users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\gradio\\outputs.py:197: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\gradio\\outputs.py:200: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  super().__init__(num_top_classes=num_top_classes, type=type, label=label)\n",
      "C:\\Users\\arjun\\AppData\\Local\\Temp\\ipykernel_15376\\3660934537.py:4: UserWarning: `capture_session` parameter is deprecated, and it has no effect\n",
      "  gr.Interface(fn=predict_image, inputs=image, outputs=label, capture_session=True).launch(debug=\"True\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image=gr.inputs.Image(shape=(227,227))\n",
    "label=gr.outputs.Label(num_top_classes=2)\n",
    "\n",
    "gr.Interface(fn=predict_image, inputs=image, outputs=label, capture_session=True).launch(debug=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
